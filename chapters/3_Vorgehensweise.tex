\chapter{Vorgehensweise}

Im Folgenden wird erklärt, wie bei der Erarbeitung der Arbeit vorgegangen wird.
Grob gesehen, werden zuerst Metriken ermittelt, diese dann in einer Software regelmäßig erzeugt, gespeichert und angezeigt.
Zuletzt wird das Ergebnis der Arbeit evaluiert.

\section{Metriken bestimmen}

Das Unternehmen, in dem die Tests durchgeführt werden, arbeitet seit rund einem Jahr nach dem Scrum Framework.
Als Basis zur Bestimmung der Metriken können daher die vorhandenen Retrospektiven genutzt werden, da diese eine Richtung vorgeben, in die sich das Team bewegen will.
Es können die meistgenutzten Schlagwörter aus den Fragestellungen der Retrospektive ermittelt werden und nach dem \ac{GQM}-Modell in Metriken abgebildet werden.
Das \ac{FCM}-Modell ist hier weniger geeignet, da die Teams in dem Unternehmen, in dem die Software getestet wird, nicht an einem Produkt arbeiten, sondern an Geschäftsprozessen und sie ebenfalls den Scrum-Prozess verbessern wollen, nicht nur ein Produkt.
\\
\\
Als Ergänzung zum \ac{GQM}-Modell wird zusätzlich das Team in einer Umfrage zu möglichen Metriken befragt.
Dabei werden die in dieser Arbeit erarbeiteten Metriken genauer vorgestellt und von den Teammitgliedern bewertet.
Dadurch soll zusätzlich die Möglichkeit gegeben werden, Metriken oder Probleme, die zuvor nicht genannt wurden, angeben zu können.
Außerdem können die Ergebnisse des \ac{GQM}-Modells mit denen der Umfrage verglichen werden.

\clearpage
\section{Software}

Im Rahmen dieser Arbeit wird eine Software entwickelt, die Qualitätsmetriken aus unterschiedlichen Systemen ermitteln und bereitstellen kann.
Dabei sollen die zuvor ermittelten Metriken automatisch erzeugt und gespeichert werden.

\subsection{Anforderungen}\label{vorgehen:software}

Die Anforderungen an die Software entstanden zum einen aus der gewünschten Funktionsweise und zum anderen aus den Gegebenheiten des Umfelds der Software (und dem Unternehmen, in dem sie getestet werden soll).

\begin{description}
    \item[Erweiterbarkeit] \hfill \\ Um einfach neue Systeme und Metriken bereitstellen zu können, muss bei der Architektur auf eine einfache Erweiterbarkeit geachtet werden.
    \item[Fehlertoleranz] \hfill \\ Ein Fehler in einem einzelnen System, das Daten bereitstellt, darf nicht zum Absturz der Software führen.
    \item[Umsetzung in Java] \hfill \\ Java ist in vielen Unternehmen verbreitet und stößt daher auf eine hohe Akzeptanz.
    \item[einzubindende Systeme] \hfill \\ Metriken können in BitBucket Server~\footcite{bitbucket_server}, JIRA~\footcite{jira}, Jenkins~\footcite{jenkins}, SonarQube~\footcite{sonarqube}, Icinga~\footcite{icinga} vorkommen, da sie vom Unternehmen eingesetzt werden, in dem die Tests stattfinden. Systeme in denen relevante Metriken ermittelt wurden, müssen unterstützt werden.
    \item[Speicherung und Darstellung] \hfill \\ Speicherung und Darstellung der Metriken erfolgt in einem Elastic Stack~\footcite{elastic_stack}, da dieser ebenfalls bereits im Unternehmen vorhanden ist, in dem sie Tests stattfinden.
\end{description}

\clearpage
\section{Evaluierung}

Nach der Fertigstellung der Software wird diese für Testzwecke in einem Unternehmen für mehrere Sprints eingesetzt, um über einen möglichst langen Zeitraum Metriken zu sammeln.
Parallel dazu wird den betroffenen Teammitgliedern der Umgang mit dem Dashboard näher gebracht.
\\
Die Evaluierung wird zum Einen quantitativ durchgeführt, da sich Metriken sehr gut dafür eignen.
Allerdings kann es sein, dass die Zeit, die für den Test zur Verfügung steht, einfach zu kurz ist, um eine Tendenz in den Metriken erkennen zu können.
\\
Daher wird zum Anderen noch eine qualitative Evaluierung durchgeführt, in Form eines Interviews mit ausgewählten Teammitgliedern.
Dies dient dazu, die Effektivität der eingesetzten Methoden ermitteln zu können und das subjektive Empfinden gegenüber der Nützlichkeit von Metriken im agilen Prozess zu erfragen.
